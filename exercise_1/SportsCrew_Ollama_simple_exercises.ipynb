{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c864d3",
   "metadata": {},
   "source": [
    "\n",
    "# üìù SportsCrew ¬∑ **Ollama (ejercicio para alumnos)**\n",
    "Completa las celdas marcadas con **TODO**. Hay **pistas** en los comentarios de cada celda.\n",
    "\n",
    "**Objetivo**: generar un *art√≠culo breve* y **5 tweets** sobre una liga deportiva usando **Ollama (mistral)** con **CrewAI**.\n",
    "\n",
    "**Documentaci√≥n √∫til**\n",
    "- **Ollama (oficial):** https://github.com/ollama/ollama  \n",
    "- **CrewAI (conceptos):** https://docs.crewai.com/concepts/  \n",
    "- **CrewAI (API referencia):** https://docs.crewai.com/reference/  \n",
    "- **LiteLLM (enrutador):** https://docs.litellm.ai/  \n",
    "- **LangChain (ecosistema):** https://python.langchain.com/docs/  \n",
    "- **DuckDuckGo (herramienta LC):** https://python.langchain.com/docs/integrations/tools/ddg  \n",
    "- **Requests (HTTP):** https://requests.readthedocs.io/  \n",
    "- **python-dotenv:** https://github.com/theskumar/python-dotenv  \n",
    "- **json (stdlib):** https://docs.python.org/3/library/json.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87305c53",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Instalar dependencias en este kernel\n",
    "Rellena la lista `packages` con las librer√≠as necesarias y completa la llamada a `pip install`.\n",
    "\n",
    "**Pistas**:\n",
    "- Necesitar√°s: `crewai`, `litellm`, `langchain`, `langchain-community`, `langchain-openai`, `duckduckgo-search`, `requests`, `python-dotenv`.\n",
    "- Usa `sys.executable -m pip install -U ...` para asegurar instalaci√≥n en este kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee5c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todo estaba instalado ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys, subprocess\n",
    "packages = [\n",
    "    \"crewai>=0.63.6\",\n",
    "    \"litellm>=1.40.11\",\n",
    "    \"langchain>=0.2.10\",\n",
    "    \"langchain-community>=0.2.10\",\n",
    "    \"langchain-openai\",\n",
    "    \"duckduckgo-search\",\n",
    "    \"requests\",\n",
    "    \"python-dotenv\"\n",
    "]\n",
    "to_install = []\n",
    "for spec in packages:\n",
    "    mod = spec.split(\"==\")[0].split(\">=\")[0].replace(\"-\", \"_\")\n",
    "    try:\n",
    "        importlib.import_module(mod if mod!=\"python_dotenv\" else \"dotenv\")\n",
    "    except Exception:\n",
    "        to_install.append(spec)\n",
    "if to_install:\n",
    "    print(\"Instalando:\", to_install)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", *to_install])\n",
    "else:\n",
    "    print(\"Todo estaba instalado ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490e526",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Comprobar **Ollama** y el modelo `mistral`\n",
    "Debes verificar que:\n",
    "1) El binario `ollama` est√° en el PATH.\n",
    "2) La API local responde en `http://localhost:11434/api/tags`.\n",
    "3) El modelo `mistral` est√° descargado.\n",
    "\n",
    "**Pistas**:\n",
    "- Usa `shutil.which(\"ollama\")` para comprobar el binario.\n",
    "- Usa `requests.get(url, timeout=5)` y revisa `resp.ok`.\n",
    "- La respuesta JSON tiene una clave `models` con nombres; busca `\"mistral\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e953fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binario 'ollama' en PATH: ‚úÖ\n",
      "Ollama API: ‚úÖ OK\n",
      "Modelos locales: ['mistral:instruct', 'mistral:latest']\n",
      "'mistral' presente: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import shutil, requests\n",
    "print(\"Binario 'ollama' en PATH:\", \"‚úÖ\" if shutil.which(\"ollama\") else \"‚ùå\")\n",
    "try:\n",
    "    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "    if r.ok:\n",
    "        tags = [m.get(\"name\") for m in r.json().get(\"models\", []) if isinstance(m, dict)]\n",
    "        print(\"Ollama API:\", \"‚úÖ OK\")\n",
    "        print(\"Modelos locales:\", tags)\n",
    "        print(\"'mistral' presente:\", \"‚úÖ\" if any(\"mistral\" in (t or \"\") for t in tags) else \"‚ùå (ejecuta: ollama pull mistral)\")\n",
    "    else:\n",
    "        print(\"Ollama API respondi√≥ con error HTTP:\", r.status_code)\n",
    "except Exception as e:\n",
    "    print(\"No se pudo conectar a http://localhost:11434. ¬øEjecutaste 'ollama serve'?\")\n",
    "    print(\"Detalle:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905dea1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3) Elegir deporte y liga\n",
    "Cambia estos valores si quieres otra competici√≥n. Ejemplos:\n",
    "1. **soccer**: \n",
    "- `esp.1` (LaLiga)\n",
    "- `eng.1` (Premier)\n",
    "- `ita.1` (Calcio)\n",
    "- `fra.1` (ligue 1) \n",
    "- `usa.1` (MLS)\n",
    "2. **basketball**: \n",
    "- `nba`\n",
    "- `wnba`\n",
    "3. **football**: \n",
    "- `nfl` \n",
    "4. **baseball**: \n",
    "- `mlb` \n",
    "5. **hockey**: \n",
    "- `nhl`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e7bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deporte: soccer | Liga: esp.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SPORT = \"soccer\"\n",
    "LEAGUE = \"esp.1\"\n",
    "MAX_ARTICLES = 5\n",
    "print(\"Deporte:\", SPORT, \"| Liga:\", LEAGUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71bed8",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Descargar noticias (ESPN)\n",
    "Construye la URL y parsea el JSON. Guarda los art√≠culos en `articles` (m√°ximo `MAX_ARTICLES`).\n",
    "\n",
    "**Pistas**:\n",
    "- URL base: `http://site.api.espn.com/apis/site/v2/sports/{sport}/{league}/news`\n",
    "- A veces los datos est√°n en `data[\"articles\"]`; otras en `data[\"feed\"][\"entries\"]`.\n",
    "- Para `entries`, normaliza a `{\"headline\": ...}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27046f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art√≠culos encontrados: 6\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_news_url(sport, league):\n",
    "    \"\"\"\n",
    "    Genera la URL para obtener noticias de ESPN seg√∫n el deporte y la liga.\n",
    "\n",
    "    Args:\n",
    "        sport (str): Deporte (por ejemplo, \"soccer\").\n",
    "        league (str): Liga espec√≠fica (por ejemplo, \"esp.1\" para LaLiga).\n",
    "\n",
    "    Returns:\n",
    "        str: URL para obtener las noticias.\n",
    "    \"\"\"\n",
    "    return f\"http://site.api.espn.com/apis/site/v2/sports/{sport}/{league}/news\"\n",
    "\n",
    "# Construye la URL para el deporte y la liga seleccionados.\n",
    "url = get_news_url(SPORT, LEAGUE)\n",
    "\n",
    "# Realiza una solicitud HTTP para obtener las noticias.\n",
    "resp = requests.get(url, timeout=15)\n",
    "resp.raise_for_status()  # Lanza una excepci√≥n si la solicitud falla.\n",
    "\n",
    "# Procesa la respuesta JSON.\n",
    "data = resp.json()\n",
    "articles = []  # Lista para almacenar los art√≠culos.\n",
    "\n",
    "# Extrae los art√≠culos de la respuesta si el formato es v√°lido.\n",
    "if isinstance(data, dict):\n",
    "    if \"articles\" in data and isinstance(data[\"articles\"], list):\n",
    "        # Si la clave \"articles\" est√° presente, utiliza su contenido.\n",
    "        articles = data[\"articles\"]\n",
    "    elif \"feed\" in data and isinstance(data[\"feed\"], dict):\n",
    "        # Si la clave \"feed\" est√° presente, extrae los titulares de las entradas.\n",
    "        entries = data[\"feed\"].get(\"entries\", [])\n",
    "        articles = [{\"headline\": e.get(\"headline\") or e.get(\"title\", \"\")} for e in entries]\n",
    "\n",
    "# Imprime la cantidad de art√≠culos encontrados.\n",
    "print(f\"Art√≠culos encontrados: {len(articles)}\")\n",
    "\n",
    "# Si no se encontraron art√≠culos, muestra un mensaje.\n",
    "if not articles:\n",
    "    print(\"No hay noticias ahora mismo. Prueba otra liga o vuelve m√°s tarde.\")\n",
    "\n",
    "# Limita el n√∫mero de art√≠culos a procesar seg√∫n MAX_ARTICLES.\n",
    "articles = articles[:MAX_ARTICLES]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c63289",
   "metadata": {},
   "source": [
    "\n",
    "## 5) B√∫squeda r√°pida (opcional) con DuckDuckGo\n",
    "Intenta crear un wrapper y un `run` de b√∫squeda para obtener contexto por titular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2845c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "    try:\n",
    "        from langchain_community.tools import DuckDuckGoSearchRun\n",
    "    except Exception:\n",
    "        from langchain.tools import DuckDuckGoSearchRun\n",
    "    ddg = DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region=\"us-en\", time=\"d\"))\n",
    "except Exception as e:\n",
    "    ddg = None\n",
    "    print(\"DuckDuckGo no disponible, seguimos sin b√∫squeda. Detalle:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20612784",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Configurar el modelo (Ollama ¬∑ mistral) para CrewAI\n",
    "Crea un `LLM` de CrewAI que apunte a Ollama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12bfccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM listo ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# Configura el modelo de lenguaje LLM utilizando Ollama.\n",
    "llm = LLM(\n",
    "    model=\"ollama/mistral\",  # Especifica el modelo local \"mistral\" de Ollama.\n",
    "    base_url=\"http://localhost:11434\",  # URL base para conectarse al servidor de Ollama.\n",
    "    temperature=0.2,  # Controla la aleatoriedad en las respuestas generadas.\n",
    "    api_key=\"ollama-local\"  # Clave API para autenticar el uso del modelo local.\n",
    ")\n",
    "\n",
    "# Imprime un mensaje indicando que el modelo est√° listo.\n",
    "print(\"LLM listo ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552199a4",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Res√∫menes (120‚Äì180 palabras)\n",
    "Para cada art√≠culo, crea un agente **Investigador** y genera un resumen.\n",
    "\n",
    "**Pistas**:\n",
    "- Importa: `from crewai import Agent, Task, Crew`\n",
    "- `headline = art.get(\"headline\") or art.get(\"title\") or \"\"`\n",
    "- Si `ddg` existe y hay `headline`, llama a `ddg.run(headline)` (maneja excepciones).\n",
    "- Prompt: ‚ÄúResume en 120‚Äì180 palabras. SOLO el resumen...‚Äù (a√±ade titular y contexto).\n",
    "\n",
    "Guarda cada texto en la lista `summaries`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5bdc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res√∫menes creados: 5\n"
     ]
    }
   ],
   "source": [
    "summaries = []  # Lista para almacenar los res√∫menes generados.\n",
    "for i, art in enumerate(articles, start=1):  # Itera sobre los art√≠culos descargados.\n",
    "    headline = art.get(\"headline\") or art.get(\"title\") or \"\"  # Obtiene el titular del art√≠culo.\n",
    "    ctx = \"\"  # Contexto adicional (vac√≠o por defecto).\n",
    "    if ddg and headline:  # Si DuckDuckGo est√° disponible y hay un titular:\n",
    "        try:\n",
    "            ctx = ddg.run(headline)  # Realiza una b√∫squeda r√°pida para obtener contexto adicional.\n",
    "        except Exception:\n",
    "            ctx = \"\"  # Si ocurre un error, deja el contexto vac√≠o.\n",
    "    \n",
    "    # Configura un agente con el rol de \"Investigador\" para generar res√∫menes.\n",
    "    researcher = Agent(\n",
    "        role=\"Investigador\",  # Rol del agente.\n",
    "        goal=\"Resumen claro y corto en espa√±ol.\",  # Objetivo del agente.\n",
    "        backstory=\"Resumes r√°pido.\",  # Contexto adicional del agente.\n",
    "        llm=llm,  # Modelo de lenguaje configurado.\n",
    "        allow_delegation=False  # No permite delegar tareas.\n",
    "    )\n",
    "    \n",
    "    # Define el prompt para el agente, incluyendo el titular y el contexto.\n",
    "    prompt = f\"\"\"Resume en 120‚Äì180 palabras. SOLO el resumen (sin t√≠tulo ni listas).\n",
    "Titular: {headline}\n",
    "Contexto (puede estar vac√≠o):\n",
    "{ctx}\n",
    "\"\"\"\n",
    "    # Crea una tarea para el agente con el prompt y el formato esperado del resultado.\n",
    "    task = Task(\n",
    "        agent=researcher,  # Agente encargado de la tarea.\n",
    "        description=prompt,  # Descripci√≥n de la tarea.\n",
    "        expected_output=\"Resumen en espa√±ol, 120‚Äì180 palabras.\"  # Formato esperado del resultado.\n",
    "    )\n",
    "    \n",
    "    # Ejecuta la tarea utilizando CrewAI y obtiene el resultado.\n",
    "    result = Crew(agents=[researcher], tasks=[task], verbose=0).kickoff()\n",
    "    text = str(getattr(result, \"raw_output\", result))  # Extrae el texto del resultado.\n",
    "    summaries.append(text.strip())  # Agrega el resumen a la lista, eliminando espacios innecesarios.\n",
    "\n",
    "# Imprime la cantidad de res√∫menes generados.\n",
    "print(f\"Res√∫menes creados: {len(summaries)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e133a9",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Art√≠culo (200‚Äì250 palabras, 2‚Äì3 p√°rrafos)\n",
    "Crea un agente **Periodista** y genera el art√≠culo usando los res√∫menes.\n",
    "\n",
    "**Pistas**:\n",
    "- Une `summaries` con `\\n\\n` ‚Üí `summaries_text`.\n",
    "- Agent con `role=\"Periodista Deportivo\"` y `llm=llm`.\n",
    "- Prompt claro: ‚ÄúEscribe un art√≠culo de 200‚Äì250 palabras (2‚Äì3 p√°rrafos)...‚Äù\n",
    "- Ejecuta `Crew(...).kickoff()` y guarda en `article_text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07c2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art√≠culo listo ‚úÖ\n",
      "\n",
      "Atl√©tico Madrid consigue su segundo triunfo de la temporada en LaLiga tras derrotar por 3-2 al Rayo Vallecano, gracias al hat-trick espectacular de Juli√°n √Ålvarez. El delantero argentino ha sido elogiado por Diego Simeone como \"el mejor jugador que tenemos\", lo que garantiz√≥ el lugar de Atl√©tico en las semifinales. Sin embargo, la negociaci√≥n con el jugador lleg√≥ a un punto tan tensa que no fue convocado para el partido contra Atl√©tico Tucum√°n el pasado d√≠a.\n",
      "\n",
      "En los √∫ltimos 15 encuentros entre Atletico Madrid y Rayo Vallecano, el primer equipo ha ganado en 12 ocasiones, mientras que Rayo Vallecano no ha obtenido victorias. El partido m√°s reciente termin√≥ con un marcador de 3-2 a favor de Atletico Madrid. Destacan los goles de Juli√°n √Ålvarez y Fran P√©rez por el equipo local. Barcelona tambi√©n se enfrent√≥ a Rayo Vallecano, ganando 1-2 gracias a un penal convertido por Lamine Yamal antes del tiempo de descanso, pero una gran anotaci√≥n de Fran P√©rez empat√≥ el partido.\n",
      "\n",
      "En la Liga espa√±ola de f√∫tbol, se encuentra la temporada 2025-26 y se puede seguir el ranking de cada equipo en ESPN, con su r√©cord de victorias, derrotas y empates. Los √∫ltimos partidos se pueden ver en el centro de juego actual, as√≠ como estad√≠sticas, noticias y videos de resaltos.\n",
      "\n",
      "Adem√°s, se muestran algunas propiedades en venta en diferentes ciudades: Jefferson City, MO ($179,900), Lancaster, OH ($279,950) y Carson City, NV ($599,000). Tambi√©n se incluye la b√∫squeda de propiedades recientemente vendidas en Realtor.com¬Æ.\n"
     ]
    }
   ],
   "source": [
    "summaries_text = \"\\n\\n\".join(summaries) if summaries else \"Sin res√∫menes.\"\n",
    "# Combina los res√∫menes generados en un solo texto, separados por dos saltos de l√≠nea.\n",
    "# Si no hay res√∫menes disponibles, utiliza el texto \"Sin res√∫menes.\"\n",
    "\n",
    "# Configura un agente con el rol de \"Periodista\" para generar un art√≠culo breve.\n",
    "journalist = Agent(\n",
    "    role=\"Periodista\",  # Rol del agente.\n",
    "    goal=\"Art√≠culo breve y claro en espa√±ol.\",  # Objetivo del agente.\n",
    "    backstory=\"Escribes con precisi√≥n.\",  # Contexto adicional del agente.\n",
    "    llm=llm,  # Modelo de lenguaje configurado.\n",
    "    allow_delegation=False  # No permite delegar tareas a otros agentes.\n",
    ")\n",
    "\n",
    "# Define el prompt para el agente, incluyendo los res√∫menes como base para el art√≠culo.\n",
    "article_prompt = f\"\"\"Escribe un art√≠culo en espa√±ol de 200‚Äì250 palabras (2‚Äì3 p√°rrafos). Sin listas ni encabezados.\n",
    "Basado en:\n",
    "{summaries_text}\n",
    "\"\"\"\n",
    "\n",
    "# Crea una tarea para el agente con el prompt y el formato esperado del resultado.\n",
    "article_task = Task(\n",
    "    agent=journalist,  # Agente encargado de la tarea.\n",
    "    description=article_prompt,  # Descripci√≥n de la tarea.\n",
    "    expected_output=\"Art√≠culo breve en espa√±ol (200‚Äì250 palabras).\"  # Formato esperado del resultado.\n",
    ")\n",
    "\n",
    "# Ejecuta la tarea utilizando CrewAI y obtiene el resultado.\n",
    "article_text = str(Crew(agents=[journalist], tasks=[article_task], verbose=0).kickoff())\n",
    "\n",
    "# Imprime el art√≠culo generado.\n",
    "print(\"Art√≠culo listo ‚úÖ\\n\")\n",
    "print(article_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7678d4",
   "metadata": {},
   "source": [
    "\n",
    "## 9) 5 tweets (1 l√≠nea c/u, con emojis y 1‚Äì2 hashtags)\n",
    "Crea un agente **Creador de Tweets** y genera EXACTAMENTE 5 l√≠neas numeradas (1‚Äì5).\n",
    "\n",
    "**Pistas**:\n",
    "- Cada tweet debe referirse a un **dato distinto** del art√≠culo.\n",
    "- Prompt: ‚ÄúCrea EXACTAMENTE 5 tweets numerados (1‚Äì5)... m√°x 40 palabras, 1‚Äì2 hashtags, emojis.‚Äù\n",
    "- Muestra las 5 l√≠neas resultantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41eddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= üê¶ Tweets =================\n",
      "\n",
      "1. üèÜ Atl√©tico Madrid gana 3-2 contra Rayo Vallecano gracias al hat-trick de Juli√°n √Ålvarez (#Atleti #LaLiga)\n",
      "2. üî• Alargue su r√©cord a 12 victorias en los √∫ltimos 15 encuentros frente a Rayo Vallecano (#AtletiRecord)\n",
      "3. üèÉ‚Äç‚ôÇÔ∏è Atl√©tico avanza a semifinales tras elogio de Diego Simeone sobre Juli√°n √Ålvarez (#Simeone #Alvarez)\n",
      "4. üíî No convocado para el partido contra Atl√©tico Tucum√°n debido a negociaciones tensas (#AtletiNegociaciones)\n",
      "5. üè° Propiedades en venta: Jefferson City, MO ($179,900), Lancaster, OH ($279,950) y Carson City, NV ($599,000). Busca propiedades recientemente vendidas en Realtor.com¬Æ (#Propiedades #Venta)\n"
     ]
    }
   ],
   "source": [
    "influencer = Agent(\n",
    "    role=\"Creador de Tweets\",  # Rol del agente.\n",
    "    goal=\"Escribir 5 tweets en una l√≠nea.\",  # Objetivo del agente.\n",
    "    backstory=\"Experto en X.\",  # Contexto adicional del agente.\n",
    "    llm=llm,  # Modelo de lenguaje configurado.\n",
    "    allow_delegation=False  # No permite delegar tareas.\n",
    ")\n",
    "\n",
    "# Define el prompt para el agente, incluyendo las reglas y el art√≠culo como base.\n",
    "tweets_prompt = f\"\"\"Crea EXACTAMENTE 5 tweets numerados (1‚Äì5), cada uno en UNA l√≠nea, en espa√±ol.\n",
    "Reglas: cada tweet debe referirse a un dato distinto del ART√çCULO, incluir 1‚Äì2 hashtags y emojis, m√°x 40 palabras.\n",
    "ART√çCULO:\n",
    "{article_text}\n",
    "\"\"\"\n",
    "\n",
    "# Crea una tarea para el agente con el prompt y el formato esperado del resultado.\n",
    "tweets_task = Task(\n",
    "    agent=influencer,  # Agente encargado de la tarea.\n",
    "    description=tweets_prompt,  # Descripci√≥n de la tarea.\n",
    "    expected_output=\"5 l√≠neas numeradas 1‚Äì5.\"  # Formato esperado del resultado.\n",
    ")\n",
    "\n",
    "# Ejecuta la tarea utilizando CrewAI y obtiene el resultado.\n",
    "tweets_text = str(Crew(agents=[influencer], tasks=[tweets_task], verbose=0).kickoff())\n",
    "\n",
    "# Procesa el texto generado para extraer las l√≠neas de los tweets.\n",
    "lines = [ln.strip() for ln in tweets_text.splitlines() if ln.strip()]\n",
    "\n",
    "# Verifica si se generaron exactamente 5 tweets.\n",
    "if len(lines) < 5:\n",
    "    print(\"Resultado recibido:\")\n",
    "    print(tweets_text)\n",
    "    print(\"\\nNo se detectaron 5 tweets claros. Ejecuta de nuevo esta celda.\")\n",
    "else:\n",
    "    print(\"\\n================= üê¶ Tweets =================\\n\")\n",
    "    for ln in lines[:5]:  # Imprime los primeros 5 tweets generados.\n",
    "        print(ln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a5214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unex25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
