{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d512f3",
   "metadata": {},
   "source": [
    "# üß™ PoC (Alumno) ‚Äî AuraDB + OpenAI (NL‚ÜíCypher) con **m√≠nimo preprocesamiento**\n",
    "**Meta:** experimentar qu√© devuelve el modelo con un pipeline **muy b√°sico** y reflexionar por qu√© hacen falta:\n",
    "- **limpieza de fences** (```cypher ‚Ä¶```),\n",
    "- **bloqueo de escrituras** (CREATE/MERGE/SET/DELETE/LOAD CSV‚Ä¶),\n",
    "- **validaci√≥n** antes de ejecutar.\n",
    "\n",
    "> Este cuaderno no incluye soluciones. Solo **pistas** y celdas con **TODO**.\n",
    "**√öltima actualizaci√≥n:** 2025-09-24 22:04 UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb7b1a",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Aviso\n",
    "- Usaremos `DRY_RUN = True` para **NO ejecutar** lo que devuelva el LLM.\n",
    "- No cambies esto salvo que el profe lo indique expl√≠citamente y el usuario sea **solo-lectura**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde754b",
   "metadata": {},
   "source": [
    "## 1) Instalaci√≥n r√°pida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: instala dependencias (usa %pip)\n",
    "# Pista: python-dotenv, neo4j, langchain, langchain-community, langchain-openai, tiktoken\n",
    "# %pip install -q ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eab1c8",
   "metadata": {},
   "source": [
    "## 2) Configuraci√≥n (m√≠nima)\n",
    "Objetivo: cargar `.env`, crear **llm** (ChatOpenAI) y **graph** (Neo4jGraph).\n",
    "\n",
    "**Pistas**\n",
    "- `from dotenv import load_dotenv`; `load_dotenv()`\n",
    "- Variables: `OPENAI_API_KEY`, `OPENAI_MODEL`, `NEO4J_URI`, `NEO4J_USERNAME`, `NEO4J_PASSWORD`\n",
    "- `from langchain_openai import ChatOpenAI` + `os.environ[\"OPENAI_API_KEY\"] = ...`\n",
    "- `from langchain_community.graphs import Neo4jGraph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40b5a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/qlbrzr6d0q92wypgx2t_5vpw0000gn/T/ipykernel_10875/2927984657.py:16: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRY_RUN = True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or \"<tu-openai-key>\"\n",
    "OPENAI_MODEL   = os.getenv(\"OPENAI_MODEL\")   or \"gpt-4.1-mini\"\n",
    "NEO4J_URI      = os.getenv(\"NEO4J_URI\")      or \"neo4j+s://<tu-host>.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\") or \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\") or \"<tu-contrase√±a>\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)\n",
    "\n",
    "DRY_RUN = True\n",
    "print(\"DRY_RUN =\", DRY_RUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57538c06",
   "metadata": {},
   "source": [
    "## 3) Esquema del grafo (solo referencia)\n",
    "**Pista:** `graph.refresh_schema()` y muestra un prefijo (`[:1200]`) de `graph.schema`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc26993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Movie {movieId: STRING, runtimeMin: INTEGER, grossUSD: FLOAT, year: INTEGER, description: STRING, imdbRating: FLOAT, votes: INTEGER, metascore: INTEGER, title: STRING}\n",
      "Year {value: INTEGER}\n",
      "Decade {value: INTEGER}\n",
      "RatingBand {name: STRING, min: FLOAT, max: FLOAT}\n",
      "RuntimeBand {name: STRING, min: INTEGER, max: INTEGER}\n",
      "BoxOfficeBand {name: STRING, min: FLOAT, max: FLOAT}\n",
      "Keyword {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Movie)-[:RELEASED_IN]->(:Year)\n",
      "(:Movie)-[:HAS_RATING_BAND]->(:RatingBand)\n",
      "(:Movie)-[:HAS_RUNTIME_BAND]->(:RuntimeBand)\n",
      "(:Movie)-[:HAS_BOXOFFICE_BAND]->(:BoxOfficeBand)\n",
      "(:Movie)-[:HAS_KEYWORD]->(:Keyword)\n",
      "(:Year)-[:IN_DECADE]->(:Decade)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema[:1200] + (\"...\" if len(graph.schema) > 1200 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e76ad",
   "metadata": {},
   "source": [
    "## 4) Generaci√≥n **naive** de Cypher\n",
    "Prop√≥sito: **no** prohibir escrituras ni limpiar fences para ver qu√© pasa.\n",
    "\n",
    "**Pistas**\n",
    "- Crea un `PromptTemplate` con `input_variables=[\"schema\",\"question\"]`\n",
    "- Template: \"Genera una consulta Cypher ... Esquema: {schema} ... Pregunta: {question} ... Cypher:\"\n",
    "- Funci√≥n `naive_generate_cypher(question)` que invoque el LLM con el prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2bb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "NAIVE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\",\"question\"],\n",
    "    template=(\n",
    "        \"Genera una consulta Cypher para Neo4j que responda a la pregunta.\\n\"\n",
    "        \"Esquema (para contexto):\\n{schema}\\n\\n\"\n",
    "        \"Pregunta: {question}\\n\"\n",
    "        \"Cypher:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "def naive_generate_cypher(question: str) -> str:\n",
    "    prompt = NAIVE_PROMPT.format(schema=graph.schema, question=question)\n",
    "    return llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240710e9",
   "metadata": {},
   "source": [
    "## 5) Ejecutor **naive** (imprime y, si se decide, ejecuta)\n",
    "Por defecto, no ejecutaremos (DRY_RUN=True). Solo **imprime** el Cypher devuelto.\n",
    "\n",
    "**Pistas**\n",
    "- `naive_run(q)` debe:\n",
    "  1) Obtener texto con `naive_generate_cypher(q)`\n",
    "  2) Imprimirlo tal cual (posibles ``` o comandos peligrosos)\n",
    "  3) Si `DRY_RUN` ‚Üí devolver un dict con el texto y aviso\n",
    "  4) Si no, ejecutar `graph.query(cy_text)` en `try/except`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bb7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_run(question: str):\n",
    "    cy_text = naive_generate_cypher(question)\n",
    "    print(\"‚Äî Cypher devuelto (sin limpiar) ‚Äî\")\n",
    "    print(cy_text)\n",
    "    print(\"‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\")\n",
    "    if DRY_RUN:\n",
    "        return {\"cypher_raw\": cy_text, \"result\": \"[DRY_RUN activo: no ejecutado]\"}\n",
    "    try:\n",
    "        result = graph.query(cy_text)\n",
    "    except Exception as e:\n",
    "        result = f\"[ERROR al ejecutar] {type(e).__name__}: {e}\"\n",
    "    return {\"cypher_raw\": cy_text, \"result\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b540c",
   "metadata": {},
   "source": [
    "## 6) Demostraci√≥n A ‚Äî Caso **benigno** (lectura)\n",
    "Pide algo sencillo, por ejemplo: *\"Dame el top 5 de pel√≠culas por rating.\"*\n",
    "\n",
    "**Objetivo**\n",
    "- Ver si el modelo devuelve una consulta limpia o con fences (```).\n",
    "- Observar diferencias de estilo/estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6c53b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äî Cypher devuelto (sin limpiar) ‚Äî\n",
      "```cypher\n",
      "MATCH (m:Movie)\n",
      "RETURN m.title, m.imdbRating\n",
      "ORDER BY m.imdbRating DESC\n",
      "LIMIT 5\n",
      "```\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cypher_raw': '```cypher\\nMATCH (m:Movie)\\nRETURN m.title, m.imdbRating\\nORDER BY m.imdbRating DESC\\nLIMIT 5\\n```',\n",
       " 'result': '[DRY_RUN activo: no ejecutado]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_a = naive_run(\"Dame el top 5 de pel√≠culas por rating.\")\n",
    "out_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e82fc",
   "metadata": {},
   "source": [
    "## 7) Demostraci√≥n B ‚Äî Caso **peligroso** (escritura)\n",
    "Pide algo expl√≠citamente destructivo, p. ej.: *\"Crea una pel√≠cula de prueba...\"*\n",
    "\n",
    "**Objetivo**\n",
    "- Comprobar si el LLM devuelve `CREATE/MERGE/SET/DELETE/...`.\n",
    "- Entender por qu√© hay que **bloquear escrituras** antes de ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2580b",
   "metadata": {},
   "source": [
    "## 8) Demostraci√≥n C ‚Äî Problema de fences (```cypher)\n",
    "Muchos modelos env√≠an la respuesta en un bloque con ``` que **rompe** la ejecuci√≥n directa.\n",
    "\n",
    "**Objetivo**\n",
    "- Observar el problema y razonar c√≥mo limpiarlo m√≠nimamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ejecuta naive_run con otra pregunta de conteo (COUNT) y observa el formato\n",
    "# out_c = naive_run(\"...\")\n",
    "# out_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dc672",
   "metadata": {},
   "source": [
    "## 9) Alternativa **m√≠nima** m√°s segura (solo lectura + limpieza superficial)\n",
    "**Sin dar la soluci√≥n**, dise√±a dos funciones:\n",
    "1) `strip_fences(text)` ‚Äî Elimina ``` al inicio/fin y descarta la etiqueta inicial (p. ej., `cypher`).\n",
    "   - Pista: `.strip()`, `.startswith(\"```\")`, `.splitlines()`\n",
    "2) `minimally_safe_generate(question)` ‚Äî Usa tu naive, limpia con `strip_fences`, y **si** detectas palabras prohibidas (`CREATE|MERGE|SET|DELETE|REMOVE|DROP|LOAD CSV`), **lanza error** para proteger la BD.\n",
    "3) `minimally_safe_run(question)` ‚Äî Igual que `naive_run`, pero usando la versi√≥n ‚Äúlimpia y solo-lectura‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e386e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "WRITE_RE = re.compile(r\"\\b(CREATE|MERGE|SET|DELETE|REMOVE|DROP|LOAD\\s+CSV)\\b\", re.IGNORECASE)\n",
    "\n",
    "def strip_fences(text: str) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = t.strip(\"`\")\n",
    "        lines = t.splitlines()\n",
    "        if lines and not lines[0].strip().upper().startswith((\"MATCH\",\"CALL\",\"RETURN\",\"WITH\")):\n",
    "            lines = lines[1:]\n",
    "        t = \"\\n\".join(lines).strip()\n",
    "    return t\n",
    "\n",
    "def minimally_safe_generate(question: str) -> str:\n",
    "    raw = naive_generate_cypher(question)\n",
    "    cleaned = strip_fences(raw)\n",
    "    if WRITE_RE.search(cleaned):\n",
    "        raise ValueError(\"‚ö†Ô∏è Consulta potencialmente destructiva detectada. Bloqueada para proteger la BD.\\n\" + cleaned)\n",
    "    return cleaned\n",
    "\n",
    "def minimally_safe_run(question: str):\n",
    "    cy = minimally_safe_generate(question)\n",
    "    print(\"‚Äî Cypher (limpio y solo-lectura) ‚Äî\")\n",
    "    print(cy)\n",
    "    print(\"‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\")\n",
    "    if DRY_RUN:\n",
    "        return {\"cypher\": cy, \"result\": \"[DRY_RUN activo: no ejecutado]\"}\n",
    "    try:\n",
    "        result = graph.query(cy)\n",
    "    except Exception as e:\n",
    "        result = f\"[ERROR al ejecutar] {type(e).__name__}: {e}\"\n",
    "    return {\"cypher\": cy, \"result\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341a38e",
   "metadata": {},
   "source": [
    "## 10) Comparativa ‚Äî naive vs. m√≠nimo seguro\n",
    "Usa **la misma pregunta** (p. ej., con keywords) y compara:\n",
    "- ¬øHay diferencias en el Cypher final?\n",
    "- ¬øLa versi√≥n segura bloquea algo? ¬øQu√© y por qu√©?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c373fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### NAIVE\n",
      "‚Äî Cypher devuelto (sin limpiar) ‚Äî\n",
      "```cypher\n",
      "MATCH (m:Movie)-[:HAS_KEYWORD]->(k:Keyword {name: 'prison'})\n",
      "RETURN m\n",
      "ORDER BY m.imdbRating DESC\n",
      "LIMIT 10\n",
      "```\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
      "\n",
      "### MIN SAFE\n",
      "‚Äî Cypher (limpio y solo-lectura) ‚Äî\n",
      "MATCH (m:Movie)-[:HAS_KEYWORD]->(k:Keyword {name: 'prison'})\n",
      "RETURN m\n",
      "ORDER BY m.imdbRating DESC\n",
      "LIMIT 10\n",
      "‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'naive': {'cypher_raw': \"```cypher\\nMATCH (m:Movie)-[:HAS_KEYWORD]->(k:Keyword {name: 'prison'})\\nRETURN m\\nORDER BY m.imdbRating DESC\\nLIMIT 10\\n```\",\n",
       "  'result': '[DRY_RUN activo: no ejecutado]'},\n",
       " 'safe': {'cypher': \"MATCH (m:Movie)-[:HAS_KEYWORD]->(k:Keyword {name: 'prison'})\\nRETURN m\\nORDER BY m.imdbRating DESC\\nLIMIT 10\",\n",
       "  'result': '[DRY_RUN activo: no ejecutado]'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"### NAIVE\")\n",
    "naive = naive_run(\"Dame 10 pel√≠culas con 'prison' entre las keywords, ordenadas por rating.\")\n",
    "print(\"\\n### MIN SAFE\")\n",
    "safe = minimally_safe_run(\"Dame 10 pel√≠culas con 'prison' entre las keywords, ordenadas por rating.\")\n",
    "{\"naive\": naive, \"safe\": safe}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca22c7",
   "metadata": {},
   "source": [
    "## 12) Conclusiones\n",
    "- El LLM puede devolver **fences** y **escrituras** si no lo guiamos.\n",
    "- Con dos pasos m√≠nimos (quitar fences + bloquear escrituras) se evitan muchos problemas.\n",
    "- En el cuaderno ‚Äúdefinitivo‚Äù se a√±aden m√°s protecciones (prompts estrictos, validadores, resumen controlado)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f5522",
   "metadata": {},
   "source": [
    "## 13) Documentaci√≥n\n",
    "- AuraDB ‚Äî conectar apps: https://neo4j.com/docs/aura/connecting-applications/overview/\n",
    "- Neo4j Python Driver: https://neo4j.com/docs/python-manual/current/\n",
    "- LangChain (Neo4j): https://python.langchain.com/docs/integrations/graphs/neo4j\n",
    "- Prompt Templates: https://python.langchain.com/docs/guides/prompt_templates/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unex25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
